{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNsWcL/dXrnkzzXW03QGHkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-213/Mini-Project/blob/main/mini_project_version2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJ8eGdZrlK6",
        "outputId": "b4468373-6d73-4fe9-d056-f9bd4b4f6000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vigneshvenkateswaran/bot-iot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Lxgj1MruPY",
        "outputId": "eadd0de4-7de2-4549-f97d-5f7e66c4d450"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot\n",
            "License(s): unknown\n",
            "Downloading bot-iot.zip to /content\n",
            "100% 1.17G/1.17G [00:11<00:00, 137MB/s]\n",
            "100% 1.17G/1.17G [00:11<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/bot-iot.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6RBawgBrxH-",
        "outputId": "770068ba-97c1-4c39-f22d-423b4512f2fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/bot-iot.zip\n",
            "  inflating: data_1.csv              \n",
            "  inflating: data_10.csv             \n",
            "  inflating: data_11.csv             \n",
            "  inflating: data_12.csv             \n",
            "  inflating: data_13.csv             \n",
            "  inflating: data_14.csv             \n",
            "  inflating: data_15.csv             \n",
            "  inflating: data_16.csv             \n",
            "  inflating: data_17.csv             \n",
            "  inflating: data_18.csv             \n",
            "  inflating: data_19.csv             \n",
            "  inflating: data_2.csv              \n",
            "  inflating: data_20.csv             \n",
            "  inflating: data_21.csv             \n",
            "  inflating: data_22.csv             \n",
            "  inflating: data_23.csv             \n",
            "  inflating: data_24.csv             \n",
            "  inflating: data_25.csv             \n",
            "  inflating: data_26.csv             \n",
            "  inflating: data_27.csv             \n",
            "  inflating: data_28.csv             \n",
            "  inflating: data_29.csv             \n",
            "  inflating: data_3.csv              \n",
            "  inflating: data_30.csv             \n",
            "  inflating: data_31.csv             \n",
            "  inflating: data_32.csv             \n",
            "  inflating: data_33.csv             \n",
            "  inflating: data_34.csv             \n",
            "  inflating: data_35.csv             \n",
            "  inflating: data_36.csv             \n",
            "  inflating: data_37.csv             \n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the actual path to your dataset file\n",
        "df = pd.read_csv('/content/data_1.csv')\n",
        "\n",
        "# Drop the specified columns\n",
        "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Optionally, save the modified dataset to a new CSV file\n",
        "df.to_csv('modified_dataset.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the modified dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeVutihCr5fy",
        "outputId": "47bcf8bb-50d7-4b08-e91c-cc6e08c106df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-760be56b5d39>:5: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/data_1.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pkSeqID         stime flgs proto            saddr  sport           daddr  \\\n",
            "0        1  1.526344e+09    e   arp    192.168.100.1    NaN   192.168.100.3   \n",
            "1        2  1.526344e+09    e   tcp    192.168.100.7    139   192.168.100.4   \n",
            "2        3  1.526344e+09    e   udp  192.168.100.149  51838  27.124.125.250   \n",
            "3        4  1.526344e+09    e   arp    192.168.100.4    NaN   192.168.100.7   \n",
            "4        5  1.526344e+09    e   udp   192.168.100.27  58999   192.168.100.1   \n",
            "\n",
            "   dport  pkts  bytes  ... spkts  dpkts  sbytes  dbytes       rate     srate  \\\n",
            "0    NaN     4    240  ...     2      2     120     120   0.002508  0.000836   \n",
            "1  36390    10    680  ...     5      5     350     330   0.006190  0.002751   \n",
            "2    123     2    180  ...     1      1      90      90  20.590960  0.000000   \n",
            "3    NaN    10    510  ...     5      5     210     300   0.006189  0.002751   \n",
            "4     53     4    630  ...     2      2     174     456   0.005264  0.001755   \n",
            "\n",
            "      drate  attack  category  subcategory   \n",
            "0  0.000836       0    Normal        Normal  \n",
            "1  0.002751       0    Normal        Normal  \n",
            "2  0.000000       0    Normal        Normal  \n",
            "3  0.002751       0    Normal        Normal  \n",
            "4  0.001755       0    Normal        Normal  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data types of the columns\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnldZDBfsB8U",
        "outputId": "7e7be4f9-a37e-4153-a0fc-1bcbcf680fa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pkSeqID           int64\n",
            "stime           float64\n",
            "flgs             object\n",
            "proto            object\n",
            "saddr            object\n",
            "sport            object\n",
            "daddr            object\n",
            "dport            object\n",
            "pkts              int64\n",
            "bytes             int64\n",
            "state            object\n",
            "ltime           float64\n",
            "seq               int64\n",
            "dur             float64\n",
            "mean            float64\n",
            "stddev          float64\n",
            "sum             float64\n",
            "min             float64\n",
            "max             float64\n",
            "spkts             int64\n",
            "dpkts             int64\n",
            "sbytes            int64\n",
            "dbytes            int64\n",
            "rate            float64\n",
            "srate           float64\n",
            "drate           float64\n",
            "attack            int64\n",
            "category         object\n",
            "subcategory      object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn imbalanced-learn tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL05bHNNM8wt",
        "outputId": "58954e10-260a-471d-993c-7b502bdaa9eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/data_1.csv')\n",
        "\n",
        "# Step 1: Drop unnecessary columns\n",
        "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco', 'sport', 'dport']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Step 2: Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "df['attack'] = label_encoder.fit_transform(df['attack'])\n",
        "\n",
        "# One-hot encoding for categorical columns\n",
        "categorical_columns = ['flgs', 'proto', 'state', 'category', 'subcategory ', 'saddr', 'daddr']\n",
        "df = pd.get_dummies(df, columns=categorical_columns)\n",
        "\n",
        "# Step 3: Normalize numerical columns\n",
        "numerical_columns = ['stime', 'ltime', 'seq', 'dur', 'mean', 'stddev', 'sum',\n",
        "                     'min', 'max', 'pkts', 'bytes', 'spkts', 'dpkts', 'sbytes',\n",
        "                     'dbytes', 'rate', 'srate', 'drate']\n",
        "\n",
        "# Ensure all numerical columns are of float type\n",
        "df[numerical_columns] = df[numerical_columns].astype(float)\n",
        "\n",
        "# Normalize numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Step 4: Split the data into features (X) and target (y)\n",
        "X = df.drop('attack', axis=1)\n",
        "y = df['attack'].astype(int)  # Ensure y is of integer type\n",
        "\n",
        "# Step 5: Oversample the minority class using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Step 6: Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input data to fit a 1D CNN\n",
        "X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1).astype(float)  # (samples, features, 1)\n",
        "X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1).astype(float)      # (samples, features, 1)\n",
        "\n",
        "# Check the shapes and data types\n",
        "print(f\"Training data shape for 1D CNN: {X_train_cnn.shape}, dtype: {X_train_cnn.dtype}\")\n",
        "print(f\"Test data shape for 1D CNN: {X_test_cnn.shape}, dtype: {X_test_cnn.dtype}\")\n",
        "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
        "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhWWc5SaMYgf",
        "outputId": "e3e576ca-242c-4443-a6a0-752ec4bfdd67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-1605f8a8c797>:12: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/data_1.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape for 1D CNN: (1596811, 242, 1), dtype: float64\n",
            "Test data shape for 1D CNN: (399203, 242, 1), dtype: float64\n",
            "y_train shape: (1596811,), dtype: int64\n",
            "y_test shape: (399203,), dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYqo4wuOSdmT",
        "outputId": "3bb80149-d52a-4795-db46-bc9379ffe48f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack\n",
            "1    798629\n",
            "0    798182\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Custom Callback to display progress bar for accuracy and batch\n",
        "class AccuracyProgressBar(Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epochs = 0\n",
        "        self.progress_bar = None\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epochs += 1\n",
        "        self.progress_bar = tqdm(total=self.params['steps'], position=0, leave=True)\n",
        "        self.progress_bar.set_description(f'Epoch {self.epochs}/{self.params[\"epochs\"]}')\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        self.progress_bar.set_postfix(accuracy=accuracy)\n",
        "        self.progress_bar.update(1)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.progress_bar.close()\n"
      ],
      "metadata": {
        "id": "4uuapAhou7TQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/data_1.csv', low_memory=False)\n",
        "\n",
        "# Inspect initial DataFrame\n",
        "print(\"Initial DataFrame shape:\", df.shape)\n",
        "print(\"Initial columns:\", df.columns)\n",
        "\n",
        "# Remove specified columns\n",
        "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco', 'sport', 'dport']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Check for and encode categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Convert all other non-numeric columns to numeric, coercing errors\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check for NaN values after conversion and fill them\n",
        "print(\"Checking for NaN values in DataFrame after conversion:\")\n",
        "print(df.isna().sum())\n",
        "df.fillna(0, inplace=True)  # Fill NaN values with 0\n",
        "\n",
        "# Split the Data into Features and Labels\n",
        "columns_to_drop = ['pkSeqID', 'attack', 'category']  # Adjust based on available columns\n",
        "X = df.drop(columns=columns_to_drop, axis=1, errors='ignore')  # Features\n",
        "y = df['attack'].values  # Labels\n",
        "\n",
        "# Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, X_train.shape[1]).astype(np.float32)\n",
        "X_test_cnn = X_test.values.reshape(-1, X_test.shape[1]).astype(np.float32)\n",
        "\n",
        "# Reshape for LSTM and RNN\n",
        "X_train_lstm_rnn = X_train.values.reshape(-1, 1, X_train.shape[1]).astype(np.float32)\n",
        "X_test_lstm_rnn = X_test.values.reshape(-1, 1, X_test.shape[1]).astype(np.float32)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "noise_factor = 0.3\n",
        "n_noisy_labels = int(len(y_train) * noise_factor)\n",
        "indices = np.random.choice(len(y_train), n_noisy_labels, replace=False)\n",
        "y_train_noisy = y_train.copy()\n",
        "y_train_noisy[indices] = np.random.choice(np.unique(y_train), n_noisy_labels)\n",
        "\n",
        "# One-hot encode noisy labels\n",
        "y_train_noisy_cat = to_categorical(y_train_noisy)"
      ],
      "metadata": {
        "id": "7e9XmIZSUUYz",
        "outputId": "f1c72ef3-22ca-4310-cb98-ff0e8e7e9c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame shape: (1000000, 35)\n",
            "Initial columns: Index(['pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport', 'daddr', 'dport',\n",
            "       'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur', 'mean', 'stddev',\n",
            "       'smac', 'dmac', 'sum', 'min', 'max', 'soui', 'doui', 'sco', 'dco',\n",
            "       'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate',\n",
            "       'attack', 'category', 'subcategory '],\n",
            "      dtype='object')\n",
            "Checking for NaN values in DataFrame after conversion:\n",
            "pkSeqID         0\n",
            "stime           0\n",
            "flgs            0\n",
            "proto           0\n",
            "saddr           0\n",
            "daddr           0\n",
            "pkts            0\n",
            "bytes           0\n",
            "state           0\n",
            "ltime           0\n",
            "seq             0\n",
            "dur             0\n",
            "mean            0\n",
            "stddev          0\n",
            "sum             0\n",
            "min             0\n",
            "max             0\n",
            "spkts           0\n",
            "dpkts           0\n",
            "sbytes          0\n",
            "dbytes          0\n",
            "rate            0\n",
            "srate           0\n",
            "drate           0\n",
            "attack          0\n",
            "category        0\n",
            "subcategory     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model creation function\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(y_train_noisy_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the model\n",
        "cnn_model = create_cnn_model((X_train_cnn.shape[1], 1))\n",
        "cnn_model.fit(X_train_cnn, y_train_noisy_cat, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "siYCTNeDUa3G",
        "outputId": "1ca04824-8855-4cee-b4b5-e2ed01525ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 25000/25000 [01:04<00:00, 390.45it/s, accuracy=0.944]\n",
            "Epoch 2/5: 100%|██████████| 25000/25000 [01:01<00:00, 405.55it/s, accuracy=0.948]\n",
            "Epoch 3/5: 100%|██████████| 25000/25000 [01:01<00:00, 405.65it/s, accuracy=0.948]\n",
            "Epoch 4/5: 100%|██████████| 25000/25000 [01:02<00:00, 396.84it/s, accuracy=0.948]\n",
            "Epoch 5/5: 100%|██████████| 25000/25000 [01:02<00:00, 397.00it/s, accuracy=0.948]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4fc60a7040>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_accuracy = cnn_model.evaluate(X_train_cnn, y_train_noisy_cat, verbose=0)[1]\n",
        "\n",
        "print(f\"CNN Model Accuracy: {cnn_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "MU9gZiMbZGTd",
        "outputId": "cd9477d7-42a4-4f1a-fbeb-1999685e03de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Accuracy: 0.9485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(16, input_shape=input_shape))  # Reduced units\n",
        "    model.add(Dropout(0.5))  # Increased dropout rate\n",
        "    model.add(Dense(y_train_noisy_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "rnn_model = create_rnn_model((X_train_lstm_rnn.shape[1], X_train_lstm_rnn.shape[2]))\n",
        "rnn_model.fit(X_train_lstm_rnn, y_train_noisy_cat, epochs=5, batch_size=32, verbose=0, callbacks=[AccuracyProgressBar()])"
      ],
      "metadata": {
        "id": "1ZY4p54hUuUj",
        "outputId": "1e4c4446-515c-4991-92d7-0f3c4190957f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 25000/25000 [01:10<00:00, 355.33it/s, accuracy=0.849]\n",
            "Epoch 2/5: 100%|██████████| 25000/25000 [01:07<00:00, 367.98it/s, accuracy=0.849]\n",
            "Epoch 3/5: 100%|██████████| 25000/25000 [01:07<00:00, 369.95it/s, accuracy=0.849]\n",
            "Epoch 4/5: 100%|██████████| 25000/25000 [01:10<00:00, 356.10it/s, accuracy=0.849]\n",
            "Epoch 5/5: 100%|██████████| 25000/25000 [01:06<00:00, 374.69it/s, accuracy=0.849]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4ed42a2e60>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_accuracy = rnn_model.evaluate(X_train_lstm_rnn, y_train_noisy_cat, verbose=0)[1]\n",
        "\n",
        "print(f\"RNN Model Accuracy: {rnn_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "WFbEzQ4jU4ka",
        "outputId": "98e8ed25-7d57-48d2-9cf8-9937d50ef97c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Model Accuracy: 0.8489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVGSxY2nhuzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}