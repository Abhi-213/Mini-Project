{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1j7afgbht2-3RfrzM_sgiUUx6ZFFi7HOH",
      "authorship_tag": "ABX9TyOo11mJ9qheSEM/u/dak/KZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-213/Mini-Project/blob/main/mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSSXvFMRDSFK",
        "outputId": "5867d3d0-def7-46a8-fa5b-3dd81ad1c345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mv4LXYQ0DVsr"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HqT5ZBnoD7j3"
      },
      "outputs": [],
      "source": [
        "!mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GtSap7s41ekj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukIS0ojhEKgU",
        "outputId": "5c3ab9ac-0d0e-4441-daa2-94d4ec52c3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vigneshvenkateswaran/bot-iot\n",
            "License(s): unknown\n",
            "Downloading bot-iot.zip to /content\n",
            "100% 1.17G/1.17G [00:54<00:00, 18.4MB/s]\n",
            "100% 1.17G/1.17G [00:54<00:00, 22.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d vigneshvenkateswaran/bot-iot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWIrztVREd_y",
        "outputId": "7625cedf-ecdc-4bff-eaba-a29c5c86324d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/bot-iot.zip\n",
            "  inflating: data_1.csv              \n",
            "  inflating: data_10.csv             \n",
            "  inflating: data_11.csv             \n",
            "  inflating: data_12.csv             \n",
            "  inflating: data_13.csv             \n",
            "  inflating: data_14.csv             \n",
            "  inflating: data_15.csv             \n",
            "  inflating: data_16.csv             \n",
            "  inflating: data_17.csv             \n",
            "  inflating: data_18.csv             \n",
            "  inflating: data_19.csv             \n",
            "  inflating: data_2.csv              \n",
            "  inflating: data_20.csv             \n",
            "  inflating: data_21.csv             \n",
            "  inflating: data_22.csv             \n",
            "  inflating: data_23.csv             \n",
            "  inflating: data_24.csv             \n",
            "  inflating: data_25.csv             \n",
            "  inflating: data_26.csv             \n",
            "  inflating: data_27.csv             \n",
            "  inflating: data_28.csv             \n",
            "  inflating: data_29.csv             \n",
            "  inflating: data_3.csv              \n",
            "  inflating: data_30.csv             \n",
            "  inflating: data_31.csv             \n",
            "  inflating: data_32.csv             \n",
            "  inflating: data_33.csv             \n",
            "  inflating: data_34.csv             \n",
            "  inflating: data_35.csv             \n",
            "  inflating: data_36.csv             \n",
            "  inflating: data_37.csv             \n",
            "  inflating: data_38.csv             \n",
            "  inflating: data_39.csv             \n",
            "  inflating: data_4.csv              \n",
            "  inflating: data_40.csv             \n",
            "  inflating: data_41.csv             \n",
            "  inflating: data_42.csv             \n",
            "  inflating: data_43.csv             \n",
            "  inflating: data_44.csv             \n",
            "  inflating: data_45.csv             \n",
            "  inflating: data_46.csv             \n",
            "  inflating: data_47.csv             \n",
            "  inflating: data_48.csv             \n",
            "  inflating: data_49.csv             \n",
            "  inflating: data_5.csv              \n",
            "  inflating: data_50.csv             \n",
            "  inflating: data_51.csv             \n",
            "  inflating: data_52.csv             \n",
            "  inflating: data_53.csv             \n",
            "  inflating: data_54.csv             \n",
            "  inflating: data_55.csv             \n",
            "  inflating: data_56.csv             \n",
            "  inflating: data_57.csv             \n",
            "  inflating: data_58.csv             \n",
            "  inflating: data_59.csv             \n",
            "  inflating: data_6.csv              \n",
            "  inflating: data_60.csv             \n",
            "  inflating: data_61.csv             \n",
            "  inflating: data_62.csv             \n",
            "  inflating: data_63.csv             \n",
            "  inflating: data_64.csv             \n",
            "  inflating: data_65.csv             \n",
            "  inflating: data_66.csv             \n",
            "  inflating: data_67.csv             \n",
            "  inflating: data_68.csv             \n",
            "  inflating: data_69.csv             \n",
            "  inflating: data_7.csv              \n",
            "  inflating: data_70.csv             \n",
            "  inflating: data_71.csv             \n",
            "  inflating: data_72.csv             \n",
            "  inflating: data_73.csv             \n",
            "  inflating: data_74.csv             \n",
            "  inflating: data_8.csv              \n",
            "  inflating: data_9.csv              \n",
            "  inflating: data_names.csv          \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/bot-iot.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the actual path to your dataset file\n",
        "df = pd.read_csv('/content/data_1.csv')\n",
        "\n",
        "# Drop the specified columns\n",
        "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Optionally, save the modified dataset to a new CSV file\n",
        "df.to_csv('modified_dataset.csv', index=False)\n",
        "\n",
        "# Display the first few rows of the modified dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or6npFZClAUg",
        "outputId": "b959f815-5a03-429e-b63a-7fbd9ea17a27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-760be56b5d39>:5: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/data_1.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pkSeqID         stime flgs proto            saddr  sport           daddr  \\\n",
            "0        1  1.526344e+09    e   arp    192.168.100.1    NaN   192.168.100.3   \n",
            "1        2  1.526344e+09    e   tcp    192.168.100.7    139   192.168.100.4   \n",
            "2        3  1.526344e+09    e   udp  192.168.100.149  51838  27.124.125.250   \n",
            "3        4  1.526344e+09    e   arp    192.168.100.4    NaN   192.168.100.7   \n",
            "4        5  1.526344e+09    e   udp   192.168.100.27  58999   192.168.100.1   \n",
            "\n",
            "   dport  pkts  bytes  ... spkts  dpkts  sbytes  dbytes       rate     srate  \\\n",
            "0    NaN     4    240  ...     2      2     120     120   0.002508  0.000836   \n",
            "1  36390    10    680  ...     5      5     350     330   0.006190  0.002751   \n",
            "2    123     2    180  ...     1      1      90      90  20.590960  0.000000   \n",
            "3    NaN    10    510  ...     5      5     210     300   0.006189  0.002751   \n",
            "4     53     4    630  ...     2      2     174     456   0.005264  0.001755   \n",
            "\n",
            "      drate  attack  category  subcategory   \n",
            "0  0.000836       0    Normal        Normal  \n",
            "1  0.002751       0    Normal        Normal  \n",
            "2  0.000000       0    Normal        Normal  \n",
            "3  0.002751       0    Normal        Normal  \n",
            "4  0.001755       0    Normal        Normal  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data types of the columns\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIwVSsVTt2KO",
        "outputId": "30d7047d-bcfe-4b5d-8476-49d07f304341"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pkSeqID           int64\n",
            "stime           float64\n",
            "flgs             object\n",
            "proto             int64\n",
            "saddr            object\n",
            "sport            object\n",
            "daddr            object\n",
            "dport            object\n",
            "pkts              int64\n",
            "bytes             int64\n",
            "state            object\n",
            "ltime           float64\n",
            "seq               int64\n",
            "dur             float64\n",
            "mean            float64\n",
            "stddev          float64\n",
            "smac            float64\n",
            "dmac            float64\n",
            "sum             float64\n",
            "min             float64\n",
            "max             float64\n",
            "soui            float64\n",
            "doui            float64\n",
            "sco             float64\n",
            "dco             float64\n",
            "spkts             int64\n",
            "dpkts             int64\n",
            "sbytes            int64\n",
            "dbytes            int64\n",
            "rate            float64\n",
            "srate           float64\n",
            "drate           float64\n",
            "attack            int64\n",
            "category          int64\n",
            "subcategory      object\n",
            "subcategory       int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e6szhZzIGm0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Custom Callback to display progress bar for accuracy and batch\n",
        "class AccuracyProgressBar(Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epochs = 0\n",
        "        self.progress_bar = None\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epochs += 1\n",
        "        self.progress_bar = tqdm(total=self.params['steps'], position=0, leave=True)\n",
        "        self.progress_bar.set_description(f'Epoch {self.epochs}/{self.params[\"epochs\"]}')\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        self.progress_bar.set_postfix(accuracy=accuracy)\n",
        "        self.progress_bar.update(1)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.progress_bar.close()\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/data_1.csv', low_memory=False)\n",
        "\n",
        "# Inspect initial DataFrame\n",
        "print(\"Initial DataFrame shape:\", df.shape)\n",
        "print(\"Initial columns:\", df.columns)\n",
        "\n",
        "# Remove specified columns\n",
        "columns_to_drop = ['smac', 'dmac', 'soui', 'doui', 'sco', 'dco', 'sport', 'dport']\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Check for and encode categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "for col in categorical_columns:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Convert all other non-numeric columns to numeric, coercing errors\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check for NaN values after conversion and fill them\n",
        "print(\"Checking for NaN values in DataFrame after conversion:\")\n",
        "print(df.isna().sum())\n",
        "df.fillna(0, inplace=True)  # Fill NaN values with 0\n",
        "\n",
        "# Split the Data into Features and Labels\n",
        "columns_to_drop = ['pkSeqID', 'attack', 'category']  # Adjust based on available columns\n",
        "X = df.drop(columns=columns_to_drop, axis=1, errors='ignore')  # Features\n",
        "y = df['attack'].values  # Labels\n",
        "\n",
        "# Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train_cnn = X_train.values.reshape(-1, X_train.shape[1]).astype(np.float32)\n",
        "X_test_cnn = X_test.values.reshape(-1, X_test.shape[1]).astype(np.float32)\n",
        "\n",
        "# Reshape for LSTM and RNN\n",
        "X_train_lstm_rnn = X_train.values.reshape(-1, 1, X_train.shape[1]).astype(np.float32)\n",
        "X_test_lstm_rnn = X_test.values.reshape(-1, 1, X_test.shape[1]).astype(np.float32)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Introduce label noise: Flip a small fraction of labels\n",
        "noise_factor = 0.1  # 10% noise\n",
        "n_noisy_labels = int(len(y_train) * noise_factor)\n",
        "indices = np.random.choice(len(y_train), n_noisy_labels, replace=False)\n",
        "y_train_noisy = y_train.copy()\n",
        "y_train_noisy[indices] = np.random.choice(np.unique(y_train), n_noisy_labels)\n",
        "\n",
        "# One-hot encode noisy labels\n",
        "y_train_noisy_cat = to_categorical(y_train_noisy)\n",
        "\n",
        "# CNN Model with Reduced Complexity\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, activation='relu', input_shape=input_shape))  # Reduced units\n",
        "    model.add(Dropout(0.7))  # Increased dropout rate\n",
        "    model.add(Dense(y_train_noisy_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = create_cnn_model((X_train_cnn.shape[1],))\n",
        "cnn_model.fit(X_train_cnn, y_train_noisy_cat, epochs=5, batch_size=32, verbose=0, callbacks=[AccuracyProgressBar()])\n",
        "\n",
        "# LSTM Model with Reduced Complexity\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(16, input_shape=input_shape))  # Reduced units\n",
        "    model.add(Dropout(0.7))  # Increased dropout rate\n",
        "    model.add(Dense(y_train_noisy_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lstm_model = create_lstm_model((X_train_lstm_rnn.shape[1], X_train_lstm_rnn.shape[2]))\n",
        "lstm_model.fit(X_train_lstm_rnn, y_train_noisy_cat, epochs=5, batch_size=32, verbose=0, callbacks=[AccuracyProgressBar()])\n",
        "\n",
        "# RNN Model with Reduced Complexity\n",
        "def create_rnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(16, input_shape=input_shape))  # Reduced units\n",
        "    model.add(Dropout(0.7))  # Increased dropout rate\n",
        "    model.add(Dense(y_train_noisy_cat.shape[1], activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "rnn_model = create_rnn_model((X_train_lstm_rnn.shape[1], X_train_lstm_rnn.shape[2]))\n",
        "rnn_model.fit(X_train_lstm_rnn, y_train_noisy_cat, epochs=5, batch_size=32, verbose=0, callbacks=[AccuracyProgressBar()])\n",
        "\n",
        "# Evaluate Models\n",
        "cnn_accuracy = cnn_model.evaluate(X_train_cnn, y_train_noisy_cat, verbose=0)[1]\n",
        "lstm_accuracy = lstm_model.evaluate(X_train_lstm_rnn, y_train_noisy_cat, verbose=0)[1]\n",
        "rnn_accuracy = rnn_model.evaluate(X_train_lstm_rnn, y_train_noisy_cat, verbose=0)[1]\n",
        "\n",
        "# Print model accuracies\n",
        "print(f\"CNN Model Accuracy: {cnn_accuracy:.4f}\")\n",
        "print(f\"LSTM Model Accuracy: {lstm_accuracy:.4f}\")\n",
        "print(f\"RNN Model Accuracy: {rnn_accuracy:.4f}\")\n",
        "\n",
        "# Majority Voting Classifier\n",
        "class MajorityVotingClassifier:\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "\n",
        "    def predict(self, X_cnn, X_lstm_rnn):\n",
        "        # Get predictions for CNN model\n",
        "        cnn_pred = np.argmax(self.models[0].predict(X_cnn), axis=1)  # Predictions from CNN\n",
        "        # Get predictions for LSTM model\n",
        "        lstm_pred = np.argmax(self.models[1].predict(X_lstm_rnn), axis=1)  # Predictions from LSTM\n",
        "        # Get predictions for RNN model\n",
        "        rnn_pred = np.argmax(self.models[2].predict(X_lstm_rnn), axis=1)  # Predictions from RNN\n",
        "\n",
        "        # Stack predictions and find the majority vote\n",
        "        predictions = np.vstack([cnn_pred, lstm_pred, rnn_pred])\n",
        "        majority_votes = np.array([np.bincount(pred).argmax() for pred in predictions.T])  # Majority voting\n",
        "\n",
        "        return majority_votes\n",
        "\n",
        "# Create an instance of the voting classifier\n",
        "voting_classifier = MajorityVotingClassifier(models=[cnn_model, lstm_model, rnn_model])\n",
        "\n",
        "# Make predictions using the Majority Voting Classifier\n",
        "final_predictions = voting_classifier.predict(X_test_cnn, X_test_lstm_rnn)\n",
        "\n",
        "# Print final predictions\n",
        "print(\"Final predictions from Majority Voting Classifier:\", final_predictions)\n",
        "\n",
        "# Evaluate the accuracy of the Majority Voting Classifier\n",
        "accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(f\"Majority Voting Classifier Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZf_wDaXK-G5",
        "outputId": "d7b14fdd-6aee-4fbc-8ac0-2268c063437f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial DataFrame shape: (1000000, 35)\n",
            "Initial columns: Index(['pkSeqID', 'stime', 'flgs', 'proto', 'saddr', 'sport', 'daddr', 'dport',\n",
            "       'pkts', 'bytes', 'state', 'ltime', 'seq', 'dur', 'mean', 'stddev',\n",
            "       'smac', 'dmac', 'sum', 'min', 'max', 'soui', 'doui', 'sco', 'dco',\n",
            "       'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'srate', 'drate',\n",
            "       'attack', 'category', 'subcategory '],\n",
            "      dtype='object')\n",
            "Checking for NaN values in DataFrame after conversion:\n",
            "pkSeqID         0\n",
            "stime           0\n",
            "flgs            0\n",
            "proto           0\n",
            "saddr           0\n",
            "daddr           0\n",
            "pkts            0\n",
            "bytes           0\n",
            "state           0\n",
            "ltime           0\n",
            "seq             0\n",
            "dur             0\n",
            "mean            0\n",
            "stddev          0\n",
            "sum             0\n",
            "min             0\n",
            "max             0\n",
            "spkts           0\n",
            "dpkts           0\n",
            "sbytes          0\n",
            "dbytes          0\n",
            "rate            0\n",
            "srate           0\n",
            "drate           0\n",
            "attack          0\n",
            "category        0\n",
            "subcategory     0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Epoch 1/5: 100%|██████████| 25000/25000 [03:04<00:00, 135.56it/s, accuracy=0.941]\n",
            "Epoch 2/5: 100%|██████████| 25000/25000 [03:28<00:00, 120.00it/s, accuracy=0.948]\n",
            "Epoch 3/5: 100%|██████████| 25000/25000 [03:13<00:00, 129.12it/s, accuracy=0.948]\n",
            "Epoch 4/5: 100%|██████████| 25000/25000 [03:13<00:00, 129.11it/s, accuracy=0.948]\n",
            "Epoch 5/5: 100%|██████████| 25000/25000 [03:01<00:00, 137.84it/s, accuracy=0.948]\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "Epoch 1/5: 100%|██████████| 25000/25000 [03:45<00:00, 110.94it/s, accuracy=0.946]\n",
            "Epoch 2/5: 100%|██████████| 25000/25000 [03:31<00:00, 118.43it/s, accuracy=0.948]\n",
            "Epoch 3/5: 100%|██████████| 25000/25000 [04:21<00:00, 95.57it/s, accuracy=0.948] \n",
            "Epoch 4/5: 100%|██████████| 25000/25000 [03:39<00:00, 113.95it/s, accuracy=0.948]\n",
            "Epoch 5/5: 100%|██████████| 25000/25000 [04:14<00:00, 98.14it/s, accuracy=0.948] \n",
            "Epoch 1/5: 100%|██████████| 25000/25000 [03:32<00:00, 117.46it/s, accuracy=0.947]\n",
            "Epoch 2/5: 100%|██████████| 25000/25000 [04:17<00:00, 97.01it/s, accuracy=0.948] \n",
            "Epoch 3/5: 100%|██████████| 25000/25000 [04:21<00:00, 95.59it/s, accuracy=0.948] \n",
            "Epoch 4/5: 100%|██████████| 25000/25000 [04:25<00:00, 94.05it/s, accuracy=0.948] \n",
            "Epoch 5/5: 100%|██████████| 25000/25000 [04:22<00:00, 95.40it/s, accuracy=0.948] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Accuracy: 0.9481\n",
            "LSTM Model Accuracy: 0.9481\n",
            "RNN Model Accuracy: 0.9481\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
            "Final predictions from Majority Voting Classifier: [1 1 1 ... 1 1 1]\n",
            "Majority Voting Classifier Accuracy: 0.9980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nltsjmeMnVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gaffxD-SnLEv"
      }
    }
  ]
}